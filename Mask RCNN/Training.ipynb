{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SsZZV2N5QgZ3","executionInfo":{"status":"ok","timestamp":1639727419901,"user_tz":-330,"elapsed":64257,"user":{"displayName":"Vinod Indi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11215792583296439240"}},"outputId":"116d384e-4b03-471b-9f55-8c0507c638ad"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gbgBQ45uTl2G","executionInfo":{"status":"ok","timestamp":1639727423315,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vinod Indi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11215792583296439240"}},"outputId":"6f9633b6-e967-4e24-e9c0-2014eaa334df"},"source":["%cd '/content/drive/MyDrive/Project'"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/11CaULD0eo2bzOUTXLY-_ejaxtRENy7I7/Project\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h-0ZLVvTQND2","executionInfo":{"status":"ok","timestamp":1639727448900,"user_tz":-330,"elapsed":23139,"user":{"displayName":"Vinod Indi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11215792583296439240"}},"outputId":"cac800c2-197e-4be0-9a86-00433411787e"},"source":["!pip uninstall keras -y\n","!pip uninstall keras-nightly -y\n","!pip uninstall keras-Preprocessing -y\n","!pip uninstall keras-vis -y\n","!pip uninstall tensorflow -y\n","!pip uninstall h5py -y"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: keras 2.7.0\n","Uninstalling keras-2.7.0:\n","  Successfully uninstalled keras-2.7.0\n","\u001b[33mWARNING: Skipping keras-nightly as it is not installed.\u001b[0m\n","Found existing installation: Keras-Preprocessing 1.1.2\n","Uninstalling Keras-Preprocessing-1.1.2:\n","  Successfully uninstalled Keras-Preprocessing-1.1.2\n","Found existing installation: keras-vis 0.4.1\n","Uninstalling keras-vis-0.4.1:\n","  Successfully uninstalled keras-vis-0.4.1\n","Found existing installation: tensorflow 2.7.0\n","Uninstalling tensorflow-2.7.0:\n","  Successfully uninstalled tensorflow-2.7.0\n","Found existing installation: h5py 3.1.0\n","Uninstalling h5py-3.1.0:\n","  Successfully uninstalled h5py-3.1.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TKS4AENuQjod","executionInfo":{"status":"ok","timestamp":1639727503980,"user_tz":-330,"elapsed":55090,"user":{"displayName":"Vinod Indi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11215792583296439240"}},"outputId":"07d03db9-6e3b-4555-baa6-c7c963d7271a"},"source":["!pip install tensorflow-gpu==1.13.1\n","!pip install keras==2.1.0\n","!pip install h5py==2.10.0"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-gpu==1.13.1\n","  Downloading tensorflow_gpu-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (345.0 MB)\n","\u001b[K     |████████████████████████████████| 345.0 MB 4.0 kB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.42.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.37.0)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.12.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.19.5)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.4.0)\n","Collecting keras-preprocessing>=1.0.5\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (3.17.3)\n","Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n","  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n","\u001b[K     |████████████████████████████████| 367 kB 46.3 MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n","Collecting keras-applications>=1.0.6\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 5.8 MB/s \n","\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0\n","  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n","\u001b[K     |████████████████████████████████| 3.2 MB 15.7 MB/s \n","\u001b[?25hCollecting h5py\n","  Downloading h5py-3.6.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n","\u001b[K     |████████████████████████████████| 4.1 MB 37.7 MB/s \n","\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.3.6)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.10.0.2)\n","Collecting mock>=2.0.0\n","  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (1.5.2)\n","Installing collected packages: mock, h5py, tensorflow-estimator, tensorboard, keras-preprocessing, keras-applications, tensorflow-gpu\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.7.0\n","    Uninstalling tensorflow-estimator-2.7.0:\n","      Successfully uninstalled tensorflow-estimator-2.7.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.7.0\n","    Uninstalling tensorboard-2.7.0:\n","      Successfully uninstalled tensorboard-2.7.0\n","Successfully installed h5py-3.6.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 mock-4.0.3 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n","Collecting keras==2.1.0\n","  Downloading Keras-2.1.0-py2.py3-none-any.whl (302 kB)\n","\u001b[K     |████████████████████████████████| 302 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.0) (1.15.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.0) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.0) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.0) (1.19.5)\n","Installing collected packages: keras\n","Successfully installed keras-2.1.0\n","Collecting h5py==2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n","Installing collected packages: h5py\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.6.0\n","    Uninstalling h5py-3.6.0:\n","      Successfully uninstalled h5py-3.6.0\n","Successfully installed h5py-2.10.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XYKtM3gbQqnr","executionInfo":{"status":"ok","timestamp":1639727516910,"user_tz":-330,"elapsed":12357,"user":{"displayName":"Vinod Indi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11215792583296439240"}},"outputId":"6cdf1e56-f6ee-4975-e640-f0fc6598b3fb"},"source":["import torch\n","import os\n","import cv2\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","import albumentations\n","import albumentations.pytorch\n","import json\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","%matplotlib inline\n","import sys\n","from mrcnn.visualize import display_instances\n","from mrcnn.config import Config\n","from mrcnn import model as modellib, utils\n","import skimage.draw\n","import numpy as np\n","from array import *\n","\n","import albumentations\n","import albumentations.pytorch"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","Using TensorFlow backend.\n"]}]},{"cell_type":"code","metadata":{"id":"L7Jcip7K2kBd","executionInfo":{"status":"ok","timestamp":1639727516911,"user_tz":-330,"elapsed":26,"user":{"displayName":"Vinod Indi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11215792583296439240"}}},"source":["import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"utWtS0Ao9Bsx","executionInfo":{"status":"ok","timestamp":1639727516912,"user_tz":-330,"elapsed":24,"user":{"displayName":"Vinod Indi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11215792583296439240"}}},"source":["# COCO_WEIGHTS_PATH = os.path.join(\"/content/drive/MyDrive/Project\", \"mask_rcnn_coco.h5\")\n","\n","COCO_WEIGHTS_PATH = os.path.join(\"/content/drive/MyDrive/Project\", \"logs/object20211128T0634/mask_rcnn_object_0593.h5\")\n","\n","DEFAULT_LOGS_DIR = os.path.join(\"/content/drive/MyDrive/Project\", \"logs\")"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"K1Up5Q_f9A9i","executionInfo":{"status":"ok","timestamp":1639727516912,"user_tz":-330,"elapsed":22,"user":{"displayName":"Vinod Indi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11215792583296439240"}}},"source":["class CustomConfig(Config):\n","    \"\"\"Configuration for training on the custom  dataset.\n","    Derives from the base Config class and overrides some values.\n","    \"\"\"\n","    # Give the configuration a recognizable name\n","    NAME = \"object\"\n","\n","    # We use a GPU with 12GB memory, which can fit two images.\n","    # Adjust down if you use a smaller GPU.\n","    IMAGES_PER_GPU = 2\n","\n","    # Number of classes (including background)\n","    NUM_CLASSES = 1 + 3  # Background + phone,laptop and mobile\n","\n","    # Number of training steps per epoch\n","    STEPS_PER_EPOCH = 100\n","\n","    # Skip detections with < 90% confidence\n","    DETECTION_MIN_CONFIDENCE = 0.9\n","\n","    IMAGE_MIN_DIM = 640\n","    IMAGE_MAX_DIM = 640\n","\n","    # VALIDATION_STEPS = 10"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"THzuCTH6TQ6-","executionInfo":{"status":"ok","timestamp":1639727517817,"user_tz":-330,"elapsed":925,"user":{"displayName":"Vinod Indi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11215792583296439240"}}},"source":["class CustomDataset(utils.Dataset):\n","\n","    def load_custom(self, dataset_dir, subset):\n","        \"\"\"Load a subset of the Dog-Cat dataset.\n","        dataset_dir: Root directory of the dataset.\n","        subset: Subset to load: train or val\n","        \"\"\"\n","        # Add classes. We have only one class to add.\n","        self.add_class(\"object\", 1, \"burr\")\n","        self.add_class(\"object\", 2, \"groove\")\n","        self.add_class(\"object\", 3, \"diagonal\")\n","        # self.add_class(\"object\", 2, \"Man\")\n","\n","        self.image_path = []\n","\n","        # Train or validation dataset?\n","        assert subset in [\"train\", \"val\"]\n","        dataset_dir = os.path.join(dataset_dir, subset)\n","\n","        # Load annotations\n","        # VGG Image Annotator saves each image in the form:\n","        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n","        #   'regions': {\n","        #       '0': {\n","        #           'region_attributes': {},\n","        #           'shape_attributes': {\n","        #               'all_points_x': [...],\n","        #               'all_points_y': [...],\n","        #               'name': 'polygon'}},\n","        #       ... more regions ...\n","        #   },\n","        #   'size': 100202\n","        # }\n","        # We mostly care about the x and y coordinates of each region\n","        self.annotations1 = []\n","        # path = os.path.join(\"/content/drive/MyDrive/Project/Data/train\",\"Path.txt\")\n","        path = os.path.join(dataset_dir,\"Path2.txt\")\n","        path = open(path)\n","        for x in path:\n","            x = x.replace('\\n', '')\n","            if x.lower().endswith(('.jpg', '.png', '.jpeg')):\n","                self.image_path.append(x)\n","            elif x.lower().endswith('.json'):\n","                self.annotations1.append(x)\n","\n","        print(\"images = \",len(self.image_path))\n","        print(\"Annot = \",len(self.annotations1))\n","        \n","        # Add images\n","        for i in range(len(self.image_path)-6):\n","            x = self.annotations1[i]\n","            with open(x) as f:\n","                a = json.load(f)\n","            # Get the x, y coordinaets of points of the polygons that make up\n","            # the outline of each object instance. There are stores in the\n","            # shape_attributes (see json format above)\n","            polygons = [(np.stack(r['points'], axis=1)).tolist() for r in a['shapes']] \n","            objects = [s['label'] for s in a['shapes']]\n","            print(\"Index = \", i)\n","            name_dict = {\"burr\": 1,\"groove\": 2 ,\"diagonal\": 3}\n","            # key = tuple(name_dict)\n","            num_ids = [name_dict[a] for a in objects]\n","     \n","            # load_mask() needs the image size to convert polygons to masks.\n","            # Unfortunately, VIA doesn't include it in JSON, so we must read\n","            # the image. This is only managable since the dataset is tiny.\n","            # print(\"numids\",num_ids)\n","            image_path = self.image_path[i]\n","            image = skimage.io.imread(image_path)\n","            height, width = image.shape[:2]\n","\n","            self.add_image(\n","                \"object\",  ## for a single class just add the name here\n","                image_id=a['imagePath'],  # use file name as a unique image id\n","                path=image_path,\n","                width=width, height=height,\n","                polygons=polygons,\n","                num_ids=num_ids\n","                )\n","\n","    def load_mask(self, image_id):\n","        \"\"\"Generate instance masks for an image.\n","       Returns:\n","        masks: A bool array of shape [height, width, instance count] with\n","            one mask per instance.\n","        class_ids: a 1D array of class IDs of the instance masks.\n","        \"\"\"\n","        # If not a Dog-Cat dataset image, delegate to parent class.\n","        image_info = self.image_info[image_id]\n","        if image_info[\"source\"] != \"object\":\n","            return super(self.__class__, self).load_mask(image_id)\n","\n","        # Convert polygons to a bitmap mask of shape\n","        # [height, width, instance_count]\n","        info = self.image_info[image_id]\n","        if info[\"source\"] != \"object\":\n","            return super(self.__class__, self).load_mask(image_id)\n","        num_ids = info['num_ids']\n","        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])], dtype=np.uint8)\n","        for i, p in enumerate(info[\"polygons\"]):\n","            # Get indexes of pixels inside the polygon and set them to 1\n","        \t# rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n","            rr, cc = skimage.draw.polygon(p[1], p[0])\n","            mask[rr, cc, i] = 1\n","\n","        # Return mask, and array of class IDs of each instance. Since we have\n","        # one class ID only, we return an array of 1s\n","        # Map class names to class IDs.\n","        num_ids = np.array(num_ids, dtype=np.int32)\n","        return mask, num_ids #np.ones([mask.shape[-1]], dtype=np.int32)\n","\n","    def image_reference(self, image_id):\n","        \"\"\"Return the path of the image.\"\"\"\n","        info = self.image_info[image_id]\n","        if info[\"source\"] == \"object\":\n","            return info[\"path\"]\n","        else:\n","            super(self.__class__, self).image_reference(image_id)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"eyc7cXvgUQ3i","executionInfo":{"status":"ok","timestamp":1639727517818,"user_tz":-330,"elapsed":11,"user":{"displayName":"Vinod Indi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11215792583296439240"}}},"source":["def train(model):\n","# def train():\n","    \"\"\"Train the model.\"\"\"\n","    # Training dataset.\n","    dataset_train = CustomDataset()\n","    dataset_train.load_custom(\"/content/drive/MyDrive/Project/Data\", \"train\")\n","    dataset_train.prepare()\n","\n","    # Validation dataset\n","    dataset_val = CustomDataset()\n","    dataset_val.load_custom(\"/content/drive/MyDrive/Project/Data\", \"val\")\n","    dataset_val.prepare()\n","\n","    # *** This training schedule is an example. Update to your needs ***\n","    # Since we're using a very small dataset, and starting from\n","    # COCO trained weights, we don't need to train too long. Also,\n","    # no need to train all layers, just the heads should do it.\n","    print(\"Training network heads\")\n","    model.train(dataset_train, dataset_val,\n","                learning_rate=config.LEARNING_RATE,\n","                epochs=600,\n","                layers='heads')"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FFF-Mlz3UX35","outputId":"0db25362-703d-4233-84ca-8cef9dedfc83","executionInfo":{"status":"ok","timestamp":1639729758323,"user_tz":-330,"elapsed":2240514,"user":{"displayName":"Vinod Indi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11215792583296439240"}}},"source":["config = CustomConfig()\n","model = modellib.MaskRCNN(mode=\"training\", config=config,\n","                                  model_dir=DEFAULT_LOGS_DIR)\n","\n","weights_path = COCO_WEIGHTS_PATH\n","        # Download weights file\n","if not os.path.exists(weights_path):\n","  utils.download_trained_weights(weights_path)\n","\n","model.load_weights(weights_path, by_name=True, exclude=[\n","            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n","            \"mrcnn_bbox\", \"mrcnn_mask\"])\n","\n","train(model)\n","# train()"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1208: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1242: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","Re-starting from epoch 593\n","images =  700\n","Annot =  700\n","Index =  0\n","Index =  1\n","Index =  2\n","Index =  3\n","Index =  4\n","Index =  5\n","Index =  6\n","Index =  7\n","Index =  8\n","Index =  9\n","Index =  10\n","Index =  11\n","Index =  12\n","Index =  13\n","Index =  14\n","Index =  15\n","Index =  16\n","Index =  17\n","Index =  18\n","Index =  19\n","Index =  20\n","Index =  21\n","Index =  22\n","Index =  23\n","Index =  24\n","Index =  25\n","Index =  26\n","Index =  27\n","Index =  28\n","Index =  29\n","Index =  30\n","Index =  31\n","Index =  32\n","Index =  33\n","Index =  34\n","Index =  35\n","Index =  36\n","Index =  37\n","Index =  38\n","Index =  39\n","Index =  40\n","Index =  41\n","Index =  42\n","Index =  43\n","Index =  44\n","Index =  45\n","Index =  46\n","Index =  47\n","Index =  48\n","Index =  49\n","Index =  50\n","Index =  51\n","Index =  52\n","Index =  53\n","Index =  54\n","Index =  55\n","Index =  56\n","Index =  57\n","Index =  58\n","Index =  59\n","Index =  60\n","Index =  61\n","Index =  62\n","Index =  63\n","Index =  64\n","Index =  65\n","Index =  66\n","Index =  67\n","Index =  68\n","Index =  69\n","Index =  70\n","Index =  71\n","Index =  72\n","Index =  73\n","Index =  74\n","Index =  75\n","Index =  76\n","Index =  77\n","Index =  78\n","Index =  79\n","Index =  80\n","Index =  81\n","Index =  82\n","Index =  83\n","Index =  84\n","Index =  85\n","Index =  86\n","Index =  87\n","Index =  88\n","Index =  89\n","Index =  90\n","Index =  91\n","Index =  92\n","Index =  93\n","Index =  94\n","Index =  95\n","Index =  96\n","Index =  97\n","Index =  98\n","Index =  99\n","Index =  100\n","Index =  101\n","Index =  102\n","Index =  103\n","Index =  104\n","Index =  105\n","Index =  106\n","Index =  107\n","Index =  108\n","Index =  109\n","Index =  110\n","Index =  111\n","Index =  112\n","Index =  113\n","Index =  114\n","Index =  115\n","Index =  116\n","Index =  117\n","Index =  118\n","Index =  119\n","Index =  120\n","Index =  121\n","Index =  122\n","Index =  123\n","Index =  124\n","Index =  125\n","Index =  126\n","Index =  127\n","Index =  128\n","Index =  129\n","Index =  130\n","Index =  131\n","Index =  132\n","Index =  133\n","Index =  134\n","Index =  135\n","Index =  136\n","Index =  137\n","Index =  138\n","Index =  139\n","Index =  140\n","Index =  141\n","Index =  142\n","Index =  143\n","Index =  144\n","Index =  145\n","Index =  146\n","Index =  147\n","Index =  148\n","Index =  149\n","Index =  150\n","Index =  151\n","Index =  152\n","Index =  153\n","Index =  154\n","Index =  155\n","Index =  156\n","Index =  157\n","Index =  158\n","Index =  159\n","Index =  160\n","Index =  161\n","Index =  162\n","Index =  163\n","Index =  164\n","Index =  165\n","Index =  166\n","Index =  167\n","Index =  168\n","Index =  169\n","Index =  170\n","Index =  171\n","Index =  172\n","Index =  173\n","Index =  174\n","Index =  175\n","Index =  176\n","Index =  177\n","Index =  178\n","Index =  179\n","Index =  180\n","Index =  181\n","Index =  182\n","Index =  183\n","Index =  184\n","Index =  185\n","Index =  186\n","Index =  187\n","Index =  188\n","Index =  189\n","Index =  190\n","Index =  191\n","Index =  192\n","Index =  193\n","Index =  194\n","Index =  195\n","Index =  196\n","Index =  197\n","Index =  198\n","Index =  199\n","Index =  200\n","Index =  201\n","Index =  202\n","Index =  203\n","Index =  204\n","Index =  205\n","Index =  206\n","Index =  207\n","Index =  208\n","Index =  209\n","Index =  210\n","Index =  211\n","Index =  212\n","Index =  213\n","Index =  214\n","Index =  215\n","Index =  216\n","Index =  217\n","Index =  218\n","Index =  219\n","Index =  220\n","Index =  221\n","Index =  222\n","Index =  223\n","Index =  224\n","Index =  225\n","Index =  226\n","Index =  227\n","Index =  228\n","Index =  229\n","Index =  230\n","Index =  231\n","Index =  232\n","Index =  233\n","Index =  234\n","Index =  235\n","Index =  236\n","Index =  237\n","Index =  238\n","Index =  239\n","Index =  240\n","Index =  241\n","Index =  242\n","Index =  243\n","Index =  244\n","Index =  245\n","Index =  246\n","Index =  247\n","Index =  248\n","Index =  249\n","Index =  250\n","Index =  251\n","Index =  252\n","Index =  253\n","Index =  254\n","Index =  255\n","Index =  256\n","Index =  257\n","Index =  258\n","Index =  259\n","Index =  260\n","Index =  261\n","Index =  262\n","Index =  263\n","Index =  264\n","Index =  265\n","Index =  266\n","Index =  267\n","Index =  268\n","Index =  269\n","Index =  270\n","Index =  271\n","Index =  272\n","Index =  273\n","Index =  274\n","Index =  275\n","Index =  276\n","Index =  277\n","Index =  278\n","Index =  279\n","Index =  280\n","Index =  281\n","Index =  282\n","Index =  283\n","Index =  284\n","Index =  285\n","Index =  286\n","Index =  287\n","Index =  288\n","Index =  289\n","Index =  290\n","Index =  291\n","Index =  292\n","Index =  293\n","Index =  294\n","Index =  295\n","Index =  296\n","Index =  297\n","Index =  298\n","Index =  299\n","Index =  300\n","Index =  301\n","Index =  302\n","Index =  303\n","Index =  304\n","Index =  305\n","Index =  306\n","Index =  307\n","Index =  308\n","Index =  309\n","Index =  310\n","Index =  311\n","Index =  312\n","Index =  313\n","Index =  314\n","Index =  315\n","Index =  316\n","Index =  317\n","Index =  318\n","Index =  319\n","Index =  320\n","Index =  321\n","Index =  322\n","Index =  323\n","Index =  324\n","Index =  325\n","Index =  326\n","Index =  327\n","Index =  328\n","Index =  329\n","Index =  330\n","Index =  331\n","Index =  332\n","Index =  333\n","Index =  334\n","Index =  335\n","Index =  336\n","Index =  337\n","Index =  338\n","Index =  339\n","Index =  340\n","Index =  341\n","Index =  342\n","Index =  343\n","Index =  344\n","Index =  345\n","Index =  346\n","Index =  347\n","Index =  348\n","Index =  349\n","Index =  350\n","Index =  351\n","Index =  352\n","Index =  353\n","Index =  354\n","Index =  355\n","Index =  356\n","Index =  357\n","Index =  358\n","Index =  359\n","Index =  360\n","Index =  361\n","Index =  362\n","Index =  363\n","Index =  364\n","Index =  365\n","Index =  366\n","Index =  367\n","Index =  368\n","Index =  369\n","Index =  370\n","Index =  371\n","Index =  372\n","Index =  373\n","Index =  374\n","Index =  375\n","Index =  376\n","Index =  377\n","Index =  378\n","Index =  379\n","Index =  380\n","Index =  381\n","Index =  382\n","Index =  383\n","Index =  384\n","Index =  385\n","Index =  386\n","Index =  387\n","Index =  388\n","Index =  389\n","Index =  390\n","Index =  391\n","Index =  392\n","Index =  393\n","Index =  394\n","Index =  395\n","Index =  396\n","Index =  397\n","Index =  398\n","Index =  399\n","Index =  400\n","Index =  401\n","Index =  402\n","Index =  403\n","Index =  404\n","Index =  405\n","Index =  406\n","Index =  407\n","Index =  408\n","Index =  409\n","Index =  410\n","Index =  411\n","Index =  412\n","Index =  413\n","Index =  414\n","Index =  415\n","Index =  416\n","Index =  417\n","Index =  418\n","Index =  419\n","Index =  420\n","Index =  421\n","Index =  422\n","Index =  423\n","Index =  424\n","Index =  425\n","Index =  426\n","Index =  427\n","Index =  428\n","Index =  429\n","Index =  430\n","Index =  431\n","Index =  432\n","Index =  433\n","Index =  434\n","Index =  435\n","Index =  436\n","Index =  437\n","Index =  438\n","Index =  439\n","Index =  440\n","Index =  441\n","Index =  442\n","Index =  443\n","Index =  444\n","Index =  445\n","Index =  446\n","Index =  447\n","Index =  448\n","Index =  449\n","Index =  450\n","Index =  451\n","Index =  452\n","Index =  453\n","Index =  454\n","Index =  455\n","Index =  456\n","Index =  457\n","Index =  458\n","Index =  459\n","Index =  460\n","Index =  461\n","Index =  462\n","Index =  463\n","Index =  464\n","Index =  465\n","Index =  466\n","Index =  467\n","Index =  468\n","Index =  469\n","Index =  470\n","Index =  471\n","Index =  472\n","Index =  473\n","Index =  474\n","Index =  475\n","Index =  476\n","Index =  477\n","Index =  478\n","Index =  479\n","Index =  480\n","Index =  481\n","Index =  482\n","Index =  483\n","Index =  484\n","Index =  485\n","Index =  486\n","Index =  487\n","Index =  488\n","Index =  489\n","Index =  490\n","Index =  491\n","Index =  492\n","Index =  493\n","Index =  494\n","Index =  495\n","Index =  496\n","Index =  497\n","Index =  498\n","Index =  499\n","Index =  500\n","Index =  501\n","Index =  502\n","Index =  503\n","Index =  504\n","Index =  505\n","Index =  506\n","Index =  507\n","Index =  508\n","Index =  509\n","Index =  510\n","Index =  511\n","Index =  512\n","Index =  513\n","Index =  514\n","Index =  515\n","Index =  516\n","Index =  517\n","Index =  518\n","Index =  519\n","Index =  520\n","Index =  521\n","Index =  522\n","Index =  523\n","Index =  524\n","Index =  525\n","Index =  526\n","Index =  527\n","Index =  528\n","Index =  529\n","Index =  530\n","Index =  531\n","Index =  532\n","Index =  533\n","Index =  534\n","Index =  535\n","Index =  536\n","Index =  537\n","Index =  538\n","Index =  539\n","Index =  540\n","Index =  541\n","Index =  542\n","Index =  543\n","Index =  544\n","Index =  545\n","Index =  546\n","Index =  547\n","Index =  548\n","Index =  549\n","Index =  550\n","Index =  551\n","Index =  552\n","Index =  553\n","Index =  554\n","Index =  555\n","Index =  556\n","Index =  557\n","Index =  558\n","Index =  559\n","Index =  560\n","Index =  561\n","Index =  562\n","Index =  563\n","Index =  564\n","Index =  565\n","Index =  566\n","Index =  567\n","Index =  568\n","Index =  569\n","Index =  570\n","Index =  571\n","Index =  572\n","Index =  573\n","Index =  574\n","Index =  575\n","Index =  576\n","Index =  577\n","Index =  578\n","Index =  579\n","Index =  580\n","Index =  581\n","Index =  582\n","Index =  583\n","Index =  584\n","Index =  585\n","Index =  586\n","Index =  587\n","Index =  588\n","Index =  589\n","Index =  590\n","Index =  591\n","Index =  592\n","Index =  593\n","Index =  594\n","Index =  595\n","Index =  596\n","Index =  597\n","Index =  598\n","Index =  599\n","Index =  600\n","Index =  601\n","Index =  602\n","Index =  603\n","Index =  604\n","Index =  605\n","Index =  606\n","Index =  607\n","Index =  608\n","Index =  609\n","Index =  610\n","Index =  611\n","Index =  612\n","Index =  613\n","Index =  614\n","Index =  615\n","Index =  616\n","Index =  617\n","Index =  618\n","Index =  619\n","Index =  620\n","Index =  621\n","Index =  622\n","Index =  623\n","Index =  624\n","Index =  625\n","Index =  626\n","Index =  627\n","Index =  628\n","Index =  629\n","Index =  630\n","Index =  631\n","Index =  632\n","Index =  633\n","Index =  634\n","Index =  635\n","Index =  636\n","Index =  637\n","Index =  638\n","Index =  639\n","Index =  640\n","Index =  641\n","Index =  642\n","Index =  643\n","Index =  644\n","Index =  645\n","Index =  646\n","Index =  647\n","Index =  648\n","Index =  649\n","Index =  650\n","Index =  651\n","Index =  652\n","Index =  653\n","Index =  654\n","Index =  655\n","Index =  656\n","Index =  657\n","Index =  658\n","Index =  659\n","Index =  660\n","Index =  661\n","Index =  662\n","Index =  663\n","Index =  664\n","Index =  665\n","Index =  666\n","Index =  667\n","Index =  668\n","Index =  669\n","Index =  670\n","Index =  671\n","Index =  672\n","Index =  673\n","Index =  674\n","Index =  675\n","Index =  676\n","Index =  677\n","Index =  678\n","Index =  679\n","Index =  680\n","Index =  681\n","Index =  682\n","Index =  683\n","Index =  684\n","Index =  685\n","Index =  686\n","Index =  687\n","Index =  688\n","Index =  689\n","Index =  690\n","Index =  691\n","Index =  692\n","Index =  693\n","images =  200\n","Annot =  200\n","Index =  0\n","Index =  1\n","Index =  2\n","Index =  3\n","Index =  4\n","Index =  5\n","Index =  6\n","Index =  7\n","Index =  8\n","Index =  9\n","Index =  10\n","Index =  11\n","Index =  12\n","Index =  13\n","Index =  14\n","Index =  15\n","Index =  16\n","Index =  17\n","Index =  18\n","Index =  19\n","Index =  20\n","Index =  21\n","Index =  22\n","Index =  23\n","Index =  24\n","Index =  25\n","Index =  26\n","Index =  27\n","Index =  28\n","Index =  29\n","Index =  30\n","Index =  31\n","Index =  32\n","Index =  33\n","Index =  34\n","Index =  35\n","Index =  36\n","Index =  37\n","Index =  38\n","Index =  39\n","Index =  40\n","Index =  41\n","Index =  42\n","Index =  43\n","Index =  44\n","Index =  45\n","Index =  46\n","Index =  47\n","Index =  48\n","Index =  49\n","Index =  50\n","Index =  51\n","Index =  52\n","Index =  53\n","Index =  54\n","Index =  55\n","Index =  56\n","Index =  57\n","Index =  58\n","Index =  59\n","Index =  60\n","Index =  61\n","Index =  62\n","Index =  63\n","Index =  64\n","Index =  65\n","Index =  66\n","Index =  67\n","Index =  68\n","Index =  69\n","Index =  70\n","Index =  71\n","Index =  72\n","Index =  73\n","Index =  74\n","Index =  75\n","Index =  76\n","Index =  77\n","Index =  78\n","Index =  79\n","Index =  80\n","Index =  81\n","Index =  82\n","Index =  83\n","Index =  84\n","Index =  85\n","Index =  86\n","Index =  87\n","Index =  88\n","Index =  89\n","Index =  90\n","Index =  91\n","Index =  92\n","Index =  93\n","Index =  94\n","Index =  95\n","Index =  96\n","Index =  97\n","Index =  98\n","Index =  99\n","Index =  100\n","Index =  101\n","Index =  102\n","Index =  103\n","Index =  104\n","Index =  105\n","Index =  106\n","Index =  107\n","Index =  108\n","Index =  109\n","Index =  110\n","Index =  111\n","Index =  112\n","Index =  113\n","Index =  114\n","Index =  115\n","Index =  116\n","Index =  117\n","Index =  118\n","Index =  119\n","Index =  120\n","Index =  121\n","Index =  122\n","Index =  123\n","Index =  124\n","Index =  125\n","Index =  126\n","Index =  127\n","Index =  128\n","Index =  129\n","Index =  130\n","Index =  131\n","Index =  132\n","Index =  133\n","Index =  134\n","Index =  135\n","Index =  136\n","Index =  137\n","Index =  138\n","Index =  139\n","Index =  140\n","Index =  141\n","Index =  142\n","Index =  143\n","Index =  144\n","Index =  145\n","Index =  146\n","Index =  147\n","Index =  148\n","Index =  149\n","Index =  150\n","Index =  151\n","Index =  152\n","Index =  153\n","Index =  154\n","Index =  155\n","Index =  156\n","Index =  157\n","Index =  158\n","Index =  159\n","Index =  160\n","Index =  161\n","Index =  162\n","Index =  163\n","Index =  164\n","Index =  165\n","Index =  166\n","Index =  167\n","Index =  168\n","Index =  169\n","Index =  170\n","Index =  171\n","Index =  172\n","Index =  173\n","Index =  174\n","Index =  175\n","Index =  176\n","Index =  177\n","Index =  178\n","Index =  179\n","Index =  180\n","Index =  181\n","Index =  182\n","Index =  183\n","Index =  184\n","Index =  185\n","Index =  186\n","Index =  187\n","Index =  188\n","Index =  189\n","Index =  190\n","Index =  191\n","Index =  192\n","Index =  193\n","Training network heads\n","\n","Starting at epoch 593. LR=0.001\n","\n","Checkpoint Path: /content/drive/MyDrive/Project/logs/object20211128T0634/mask_rcnn_object_{epoch:04d}.h5\n","Selecting layers to train\n","fpn_c5p5               (Conv2D)\n","fpn_c4p4               (Conv2D)\n","fpn_c3p3               (Conv2D)\n","fpn_c2p2               (Conv2D)\n","fpn_p5                 (Conv2D)\n","fpn_p2                 (Conv2D)\n","fpn_p3                 (Conv2D)\n","fpn_p4                 (Conv2D)\n","In model:  rpn_model\n","    rpn_conv_shared        (Conv2D)\n","    rpn_class_raw          (Conv2D)\n","    rpn_bbox_pred          (Conv2D)\n","mrcnn_mask_conv1       (TimeDistributed)\n","mrcnn_mask_bn1         (TimeDistributed)\n","mrcnn_mask_conv2       (TimeDistributed)\n","mrcnn_mask_bn2         (TimeDistributed)\n","mrcnn_class_conv1      (TimeDistributed)\n","mrcnn_class_bn1        (TimeDistributed)\n","mrcnn_mask_conv3       (TimeDistributed)\n","mrcnn_mask_bn3         (TimeDistributed)\n","mrcnn_class_conv2      (TimeDistributed)\n","mrcnn_class_bn2        (TimeDistributed)\n","mrcnn_mask_conv4       (TimeDistributed)\n","mrcnn_mask_bn4         (TimeDistributed)\n","mrcnn_bbox_fc          (TimeDistributed)\n","mrcnn_mask_deconv      (TimeDistributed)\n","mrcnn_class_logits     (TimeDistributed)\n","mrcnn_mask             (TimeDistributed)\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 594/600\n","100/100 [==============================] - 241s 2s/step - loss: 0.7128 - rpn_class_loss: 7.7912e-04 - rpn_bbox_loss: 0.0245 - mrcnn_class_loss: 0.1666 - mrcnn_bbox_loss: 0.1741 - mrcnn_mask_loss: 0.3468 - val_loss: 3.0578 - val_rpn_class_loss: 0.5207 - val_rpn_bbox_loss: 0.8155 - val_mrcnn_class_loss: 0.5194 - val_mrcnn_bbox_loss: 0.4130 - val_mrcnn_mask_loss: 0.7892\n","Epoch 595/600\n"," 49/100 [=============>................] - ETA: 1:06 - loss: 0.2034 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0234 - mrcnn_class_loss: 0.0294 - mrcnn_bbox_loss: 0.0515 - mrcnn_mask_loss: 0.0971"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:Error processing image {'id': 'frame_64.jpg', 'source': 'object', 'path': '/content/drive/MyDrive/Project/Semantic segmentation/Good/Diagonal/frames_compress21_D/frame_64.jpg', 'width': 1000, 'height': 1000, 'polygons': [], 'num_ids': []}\n","Traceback (most recent call last):\n","  File \"/content/drive/.shortcut-targets-by-id/11CaULD0eo2bzOUTXLY-_ejaxtRENy7I7/Project/mrcnn/model.py\", line 1737, in data_generator\n","    use_mini_mask=config.USE_MINI_MASK)\n","  File \"/content/drive/.shortcut-targets-by-id/11CaULD0eo2bzOUTXLY-_ejaxtRENy7I7/Project/mrcnn/model.py\", line 1293, in load_image_gt\n","    class_ids = class_ids[_idx]\n","IndexError: boolean index did not match indexed array along dimension 0; dimension is 0 but corresponding boolean dimension is 512\n"]},{"output_type":"stream","name":"stdout","text":["100/100 [==============================] - 168s 2s/step - loss: 0.1759 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0202 - mrcnn_class_loss: 0.0240 - mrcnn_bbox_loss: 0.0410 - mrcnn_mask_loss: 0.0894 - val_loss: 3.4372 - val_rpn_class_loss: 0.5862 - val_rpn_bbox_loss: 0.9163 - val_mrcnn_class_loss: 0.6257 - val_mrcnn_bbox_loss: 0.4121 - val_mrcnn_mask_loss: 0.8969\n","Epoch 596/600\n","100/100 [==============================] - 167s 2s/step - loss: 0.1496 - rpn_class_loss: 7.0849e-04 - rpn_bbox_loss: 0.0167 - mrcnn_class_loss: 0.0197 - mrcnn_bbox_loss: 0.0292 - mrcnn_mask_loss: 0.0832 - val_loss: 3.2747 - val_rpn_class_loss: 0.5203 - val_rpn_bbox_loss: 0.7857 - val_mrcnn_class_loss: 0.6475 - val_mrcnn_bbox_loss: 0.3998 - val_mrcnn_mask_loss: 0.9214\n","Epoch 597/600\n"," 39/100 [==========>...................] - ETA: 1:19 - loss: 0.1593 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0184 - mrcnn_class_loss: 0.0252 - mrcnn_bbox_loss: 0.0291 - mrcnn_mask_loss: 0.0855"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:Error processing image {'id': 'frame_64.jpg', 'source': 'object', 'path': '/content/drive/MyDrive/Project/Semantic segmentation/Good/Diagonal/frames_compress21_D/frame_64.jpg', 'width': 1000, 'height': 1000, 'polygons': [], 'num_ids': []}\n","Traceback (most recent call last):\n","  File \"/content/drive/.shortcut-targets-by-id/11CaULD0eo2bzOUTXLY-_ejaxtRENy7I7/Project/mrcnn/model.py\", line 1737, in data_generator\n","    use_mini_mask=config.USE_MINI_MASK)\n","  File \"/content/drive/.shortcut-targets-by-id/11CaULD0eo2bzOUTXLY-_ejaxtRENy7I7/Project/mrcnn/model.py\", line 1293, in load_image_gt\n","    class_ids = class_ids[_idx]\n","IndexError: boolean index did not match indexed array along dimension 0; dimension is 0 but corresponding boolean dimension is 512\n"]},{"output_type":"stream","name":"stdout","text":["100/100 [==============================] - 168s 2s/step - loss: 0.1505 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0181 - mrcnn_class_loss: 0.0218 - mrcnn_bbox_loss: 0.0268 - mrcnn_mask_loss: 0.0827 - val_loss: 3.3284 - val_rpn_class_loss: 0.5039 - val_rpn_bbox_loss: 0.8077 - val_mrcnn_class_loss: 0.6342 - val_mrcnn_bbox_loss: 0.4193 - val_mrcnn_mask_loss: 0.9633\n","Epoch 598/600\n","100/100 [==============================] - 167s 2s/step - loss: 0.1475 - rpn_class_loss: 9.4824e-04 - rpn_bbox_loss: 0.0176 - mrcnn_class_loss: 0.0202 - mrcnn_bbox_loss: 0.0258 - mrcnn_mask_loss: 0.0830 - val_loss: 3.5091 - val_rpn_class_loss: 0.5805 - val_rpn_bbox_loss: 0.8968 - val_mrcnn_class_loss: 0.6738 - val_mrcnn_bbox_loss: 0.4165 - val_mrcnn_mask_loss: 0.9414\n","Epoch 599/600\n","100/100 [==============================] - 169s 2s/step - loss: 0.1432 - rpn_class_loss: 9.1562e-04 - rpn_bbox_loss: 0.0166 - mrcnn_class_loss: 0.0209 - mrcnn_bbox_loss: 0.0244 - mrcnn_mask_loss: 0.0804 - val_loss: 3.4233 - val_rpn_class_loss: 0.5503 - val_rpn_bbox_loss: 0.8244 - val_mrcnn_class_loss: 0.7420 - val_mrcnn_bbox_loss: 0.3929 - val_mrcnn_mask_loss: 0.9137\n","Epoch 600/600\n","100/100 [==============================] - 168s 2s/step - loss: 0.1520 - rpn_class_loss: 8.6254e-04 - rpn_bbox_loss: 0.0187 - mrcnn_class_loss: 0.0203 - mrcnn_bbox_loss: 0.0263 - mrcnn_mask_loss: 0.0858 - val_loss: 3.1610 - val_rpn_class_loss: 0.5010 - val_rpn_bbox_loss: 0.8200 - val_mrcnn_class_loss: 0.6000 - val_mrcnn_bbox_loss: 0.3858 - val_mrcnn_mask_loss: 0.8542\n"]}]}]}